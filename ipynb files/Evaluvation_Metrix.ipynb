{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0fde4b13-6c2a-4588-8034-60de11cb556c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TRANSFORMERS_NO_TF\"] = \"1\"\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c1a15e0-9881-4e44-9365-782c00e37d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"distilbert-base-uncased\"   # or bert-base-uncased\n",
    "MODEL_PATH = \"C:/Users/parth/Desktop/phising_Website Detection/best_model.pt\"             # your saved .pt file\n",
    "\n",
    "URL_CSV = \"C:/Users/parth/Desktop/phising_Website Detection/Phish_URL.csv\"\n",
    "EMAIL_CSV = \"C:/Users/parth/Desktop/phising_Website Detection/Phishing_Email.csv\"\n",
    "\n",
    "MAX_LEN = 128\n",
    "BATCH_SIZE = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e29919a-e8ca-476b-92f2-35c0cc03526f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_url_dataset():\n",
    "    df = pd.read_csv(URL_CSV)\n",
    "    data = pd.DataFrame()\n",
    "    data[\"text\"] = df[\"URL\"].astype(str)\n",
    "    data[\"label\"] = df[\"label\"].astype(int)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ecf8f5cd-5d05-4009-85bf-2feb172b6d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_email_dataset():\n",
    "    df = pd.read_csv(EMAIL_CSV)\n",
    "    data = pd.DataFrame()\n",
    "    data[\"text\"] = df[\"Email Text\"].astype(str)\n",
    "    data[\"label\"] = df[\"Email Type\"].apply(\n",
    "        lambda x: 1 if \"phish\" in x.lower() else 0\n",
    "    )\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23aa9851-03b0-4bec-b3fc-d453e72fa011",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_url = load_url_dataset()\n",
    "df_email = load_email_dataset()\n",
    "\n",
    "df = pd.concat([df_url, df_email], ignore_index=True)\n",
    "df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "texts = df[\"text\"].tolist()\n",
    "labels = df[\"label\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f95fc186-8bd5-4c31-b02e-2429f5288295",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "class EvalDataset(Dataset):\n",
    "    def __init__(self, texts, labels):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        enc = tokenizer(\n",
    "            self.texts[idx],\n",
    "            max_length=MAX_LEN,\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        return {\n",
    "            \"input_ids\": enc[\"input_ids\"].squeeze(),\n",
    "            \"attention_mask\": enc[\"attention_mask\"].squeeze(),\n",
    "            \"labels\": torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        }\n",
    "\n",
    "eval_ds = EvalDataset(texts, labels)\n",
    "eval_loader = DataLoader(eval_ds, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8629dfb-b313-4254-8153-37f087b65ec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME, num_labels=2\n",
    ")\n",
    "\n",
    "model.load_state_dict(torch.load(MODEL_PATH, map_location=device))\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "print(\"Model loaded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "321fe020-fafe-41d2-930f-04d1c63c5cb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\parth\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\models\\distilbert\\modeling_distilbert.py:392: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at ..\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:455.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    }
   ],
   "source": [
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in eval_loader:\n",
    "        ids = batch[\"input_ids\"].to(device)\n",
    "        mask = batch[\"attention_mask\"].to(device)\n",
    "        labels = batch[\"labels\"].to(device)\n",
    "\n",
    "        outputs = model(input_ids=ids, attention_mask=mask)\n",
    "        preds = torch.argmax(outputs.logits, dim=1)\n",
    "\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "27e51438-53d1-4301-96c0-6de641f1f912",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9969345045098155\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Legitimate       1.00      0.99      1.00    112267\n",
      "    Phishing       1.00      1.00      1.00    142178\n",
      "\n",
      "    accuracy                           1.00    254445\n",
      "   macro avg       1.00      1.00      1.00    254445\n",
      "weighted avg       1.00      1.00      1.00    254445\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\", accuracy_score(all_labels, all_preds))\n",
    "\n",
    "print(\"\\nClassification Report:\\n\")\n",
    "print(classification_report(\n",
    "    all_labels,\n",
    "    all_preds,\n",
    "    target_names=[\"Legitimate\", \"Phishing\"]\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59892c66-f723-4a83-991c-56e4289722c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
