{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2483f813-a837-4091-a2b9-39814f994ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a99b4b63-1370-440e-9532-196deca3bc98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TRANSFORMERS_NO_TF\"] = \"1\"\n",
    "\n",
    "import random\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, precision_recall_fscore_support\n",
    "from sklearn.utils import shuffle\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, get_linear_schedule_with_warmup\n",
    "from torch.optim import AdamW\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4af06586-c563-4d2c-957c-0c4902824132",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1cf90810270>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "URL_CSV = \"C:/Users/parth/Desktop/phising_Website Detection/Phish_URL.csv\"\n",
    "EMAIL_CSV = \"C:/Users/parth/Desktop/phising_Website Detection/Phishing_Email.csv\"\n",
    "\n",
    "MODEL_NAME = \"distilbert-base-uncased\"\n",
    "MAX_LEN = 128\n",
    "BATCH_SIZE = 8\n",
    "EPOCHS = 3\n",
    "LR = 2e-5\n",
    "SEED = 42\n",
    "\n",
    "torch.manual_seed(SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78c2e68b-3cfd-4aca-8045-fe2173e3564d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_url_dataset():\n",
    "    df = pd.read_csv(URL_CSV)\n",
    "\n",
    "    # Map required columns\n",
    "    df_url = pd.DataFrame()\n",
    "    df_url[\"text\"] = df[\"URL\"].astype(str)          # NLP Input\n",
    "    df_url[\"label\"] = df[\"label\"].astype(int)       # Target\n",
    "\n",
    "    return df_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "626c048d-c9c1-45db-a6a3-2183bf460834",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_email_dataset():\n",
    "    df = pd.read_csv(EMAIL_CSV)\n",
    "\n",
    "    df_email = pd.DataFrame()\n",
    "    df_email[\"text\"] = df[\"Email Text\"].astype(str)\n",
    "\n",
    "    df_email[\"label\"] = df[\"Email Type\"].apply(\n",
    "        lambda x: 1 if \"phishing\" in x.lower() else 0\n",
    "    )\n",
    "\n",
    "    return df_email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "041396a1-dc1e-499d-a3be-cfec25caff5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             text  label\n",
      "0     https://bikp11-gth.web.app/      0\n",
      "1       http://www.pornhouse.mobi      0\n",
      "2          https://www.blocku.com      1\n",
      "3       https://www.class1895.com      1\n",
      "4  https://www.countyleague.co.uk      1\n",
      "label\n",
      "1    142178\n",
      "0    112267\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df_url = load_url_dataset()\n",
    "df_email = load_email_dataset()\n",
    "\n",
    "df = pd.concat([df_url, df_email], ignore_index=True)\n",
    "df = df.sample(frac=1, random_state=SEED).reset_index(drop=True)\n",
    "\n",
    "print(df.head())\n",
    "print(df[\"label\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "52db7bd0-b273-4376-8405-7e8875a810ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = df[\"text\"].tolist()\n",
    "labels = df[\"label\"].tolist()\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    texts, labels, test_size=0.2, random_state=SEED, stratify=labels\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9faadd9b-cefe-47c9-a96d-4d36a05d5047",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, texts, labels):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        enc = tokenizer(\n",
    "            self.texts[idx],\n",
    "            max_length=MAX_LEN,\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        return {\n",
    "            \"input_ids\": enc[\"input_ids\"].squeeze(),\n",
    "            \"attention_mask\": enc[\"attention_mask\"].squeeze(),\n",
    "            \"labels\": torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        }\n",
    "\n",
    "train_ds = TextDataset(X_train, y_train)\n",
    "val_ds = TextDataset(X_val, y_val)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "26b7f0d5-d982-4c39-ae14-dd41196334a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME, num_labels=2\n",
    ").to(device)\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef418fba-d3b7-4fa9-ba37-5599dfcfa99d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\parth\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\models\\distilbert\\modeling_distilbert.py:392: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at ..\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:455.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    }
   ],
   "source": [
    "best_f1 = 0\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        ids = batch[\"input_ids\"].to(device)\n",
    "        msk = batch[\"attention_mask\"].to(device)\n",
    "        lbl = batch[\"labels\"].to(device)\n",
    "\n",
    "        out = model(ids, msk, labels=lbl)\n",
    "        loss = out.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS} - Loss: {total_loss/len(train_loader):.4f}\")\n",
    "\n",
    "    # Evaluation\n",
    "    model.eval()\n",
    "    preds, trues = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            ids = batch[\"input_ids\"].to(device)\n",
    "            msk = batch[\"attention_mask\"].to(device)\n",
    "            lbl = batch[\"labels\"].to(device)\n",
    "\n",
    "            logits = model(ids, msk).logits\n",
    "            preds.extend(torch.argmax(logits, 1).cpu().numpy())\n",
    "            trues.extend(lbl.cpu().numpy())\n",
    "\n",
    "    p, r, f1, _ = precision_recall_fscore_support(trues, preds, average=\"binary\")\n",
    "    print(\"Validation F1:\", f1)\n",
    "\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        torch.save(model.state_dict(), \"best_model.pt\")\n",
    "        print(\"Model saved with F1 =\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b7049d-272e-40bc-aa28-f8a75f0c774c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nFinal Evaluation Report:\")\n",
    "print(classification_report(trues, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7656e4b9-f422-4382-984c-20a3ef5f7d4a",
   "metadata": {},
   "source": [
    "## website model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
