{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5fd8a812-7585-47fd-b90b-dc95ec233560",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0d0fdb6-e678-4628-97d5-955f8900d5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TRANSFORMERS_NO_TF\"] = \"1\"\n",
    "\n",
    "import random\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, get_linear_schedule_with_warmup\n",
    "from torch.optim import AdamW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3fb5d92-060b-4684-8cac-5572e4e6fcae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x2e45d731630>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML_BASE_DIR = \"C:/Users/parth/Desktop/phising_Website Detection/website + Text\"\n",
    "PHISH_DIR = \"C:/Users/parth/Desktop/phising_Website Detection/website + Text/phishing_site_1\"\n",
    "GENUINE_DIR = \"C:/Users/parth/Desktop/phising_Website Detection/website + Text/genuine_site_0\"\n",
    "\n",
    "MODEL_NAME = \"distilbert-base-uncased\"\n",
    "MAX_LEN = 256\n",
    "BATCH_SIZE = 8\n",
    "EPOCHS = 1\n",
    "LR = 2e-5\n",
    "SEED = 42\n",
    "\n",
    "MODEL_SAVE_PATH = \"website_phishing_model.pt\"\n",
    "\n",
    "torch.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ed83618-b72e-4971-9174-974299683c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def fix_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b733288-4d03-4c11-9dc1-89ebc2151d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def html_to_text(content: str) -> str:\n",
    "    soup = BeautifulSoup(content, \"lxml\")\n",
    "\n",
    "    for tag in soup([\"script\", \"style\", \"noscript\"]):\n",
    "        tag.decompose()\n",
    "\n",
    "    text = soup.get_text(separator=\" \")\n",
    "    return \" \".join(text.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b48a467-aa7c-463b-8f86-5762db3a69ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def html_to_text(content: str) -> str:\n",
    "    soup = BeautifulSoup(content, \"lxml\")\n",
    "    for tag in soup([\"script\", \"style\", \"noscript\"]):\n",
    "        tag.decompose()\n",
    "    text = soup.get_text(separator=\" \")\n",
    "    return \" \".join(text.split())\n",
    "\n",
    "\n",
    "def read_text_files_from_dir(directory: Path, label: int):\n",
    "    records = []\n",
    "\n",
    "    for file in directory.iterdir():\n",
    "        if not file.is_file():\n",
    "            continue\n",
    "\n",
    "        raw = file.read_text(errors=\"ignore\").strip()\n",
    "        if len(raw) < 20:\n",
    "            continue\n",
    "\n",
    "        # Detect HTML vs plain text\n",
    "        if \"<html\" in raw.lower() or \"<body\" in raw.lower():\n",
    "            clean_text = html_to_text(raw)\n",
    "        else:\n",
    "            clean_text = raw\n",
    "\n",
    "        if len(clean_text) > 20:\n",
    "            records.append({\n",
    "                \"text\": clean_text,\n",
    "                \"label\": label\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf527831-a165-4bb4-b5b9-90ca01841f76",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\parth\\AppData\\Local\\Temp\\ipykernel_27852\\4274779888.py:6: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  soup = BeautifulSoup(content, \"lxml\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genuine samples: 1221\n",
      "Phishing samples: 500\n",
      "Final dataset shape: (1721, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ranker vote on everything Watchworthy Weird Hi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RFC 1097 - Telnet subliminal-message option Li...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sean's Home Page Sean Maschue's personal home ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>å…¬å¹³å…¬æ­£-ä¸–ç•Œæ¯-NBAå®˜æ–¹èµžåŠ©</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Page not found â€“ Cricketdiane's Weblog Skip ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  Ranker vote on everything Watchworthy Weird Hi...      0\n",
       "1  RFC 1097 - Telnet subliminal-message option Li...      0\n",
       "2  Sean's Home Page Sean Maschue's personal home ...      0\n",
       "3              å…¬å¹³å…¬æ­£-ä¸–ç•Œæ¯-NBAå®˜æ–¹èµžåŠ©      1\n",
       "4  Page not found â€“ Cricketdiane's Weblog Skip ...      0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "SEED = 42\n",
    "fix_seed(SEED)\n",
    "\n",
    "DATA_DIR = \"C:/Users/parth/Desktop/phising_Website Detection/website + Text\"\n",
    "GENUINE_SUBFOLDER = \"C:/Users/parth/Desktop/phising_Website Detection/website + Text/genuine_site_0\"\n",
    "PHISH_SUBFOLDER = \"C:/Users/parth/Desktop/phising_Website Detection/website + Text/phishing_site_1\"\n",
    "\n",
    "base = Path(DATA_DIR)\n",
    "\n",
    "df_genuine = read_text_files_from_dir(base / GENUINE_SUBFOLDER, 0)\n",
    "df_phish = read_text_files_from_dir(base / PHISH_SUBFOLDER, 1)\n",
    "\n",
    "print(\"Genuine samples:\", len(df_genuine))   # ≈ 1312 + 40\n",
    "print(\"Phishing samples:\", len(df_phish))    # ≈ 553 + 28\n",
    "\n",
    "df = pd.concat([df_genuine, df_phish], ignore_index=True)\n",
    "df = shuffle(df, random_state=SEED).reset_index(drop=True)\n",
    "\n",
    "print(\"Final dataset shape:\", df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c58ec5d9-edb4-48a0-8fd3-6544572716ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"distilbert-base-uncased\"\n",
    "MAX_LEN = 256\n",
    "BATCH_SIZE = 8\n",
    "EPOCHS = 1\n",
    "LR = 2e-5\n",
    "SEED = 42\n",
    "\n",
    "MODEL_SAVE_PATH = \"website_phishing_model.pt\"\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "206d4553-e2c6-46a7-b70d-ad387077d30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TRANSFORMERS_NO_TF\"] = \"1\"\n",
    "\n",
    "import random\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, get_linear_schedule_with_warmup\n",
    "from torch.optim import AdamW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "633efcf6-343e-4dbc-a49b-aa5047ea0a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "71ec1458-61cc-4523-b9cc-14ad0b62b3d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 1376\n",
      "Validation size: 345\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    df[\"text\"].tolist(),\n",
    "    df[\"label\"].tolist(),\n",
    "    test_size=0.2,\n",
    "    random_state=SEED,\n",
    "    stratify=df[\"label\"]\n",
    ")\n",
    "\n",
    "print(\"Train size:\", len(X_train))\n",
    "print(\"Validation size:\", len(X_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "45ae4bec-d8d5-4bbf-bb4d-5793f49154cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "86ab7b32-200a-4495-b056-28d4a67de05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WebsiteDataset(Dataset):\n",
    "    def __init__(self, texts, labels):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        enc = tokenizer(\n",
    "            self.texts[idx],\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            max_length=MAX_LEN,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        return {\n",
    "            \"input_ids\": enc[\"input_ids\"].squeeze(0),\n",
    "            \"attention_mask\": enc[\"attention_mask\"].squeeze(0),\n",
    "            \"labels\": torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3d2b704e-fd3b-49ad-9b73-627b897d0550",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    WebsiteDataset(X_train, y_train),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    WebsiteDataset(X_val, y_val),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7e065df4-7c22-45ee-a0db-ae563fad28e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    num_labels=2\n",
    ").to(device)\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "80decdb8-8d1b-4104-ac95-a234e94c9648",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\parth\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\models\\distilbert\\modeling_distilbert.py:392: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at ..\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:455.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/1\n",
      "Train Loss: 0.4352095525191967\n",
      "Validation Accuracy: 0.8348\n",
      "Validation F1-score: 0.6919\n",
      "✅ Best model saved\n"
     ]
    }
   ],
   "source": [
    "best_f1 = 0.0\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "\n",
    "    for batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        ids = batch[\"input_ids\"].to(device)\n",
    "        mask = batch[\"attention_mask\"].to(device)\n",
    "        labels = batch[\"labels\"].to(device)\n",
    "\n",
    "        outputs = model(\n",
    "            input_ids=ids,\n",
    "            attention_mask=mask,\n",
    "            labels=labels\n",
    "        )\n",
    "\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"\\nEpoch {epoch+1}/{EPOCHS}\")\n",
    "    print(\"Train Loss:\", total_loss / len(train_loader))\n",
    "\n",
    "    # ---------- Validation ----------\n",
    "    model.eval()\n",
    "    preds, trues = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            ids = batch[\"input_ids\"].to(device)\n",
    "            mask = batch[\"attention_mask\"].to(device)\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "\n",
    "            logits = model(ids, mask).logits\n",
    "            preds.extend(torch.argmax(logits, dim=1).cpu().numpy())\n",
    "            trues.extend(labels.cpu().numpy())\n",
    "\n",
    "    p, r, f1, _ = precision_recall_fscore_support(trues, preds, average=\"binary\")\n",
    "    acc = accuracy_score(trues, preds)\n",
    "\n",
    "    print(f\"Validation Accuracy: {acc:.4f}\")\n",
    "    print(f\"Validation F1-score: {f1:.4f}\")\n",
    "\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        torch.save(model.state_dict(), MODEL_SAVE_PATH)\n",
    "        print(\"✅ Best model saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ef02ea44-fa75-4ce7-8828-c97a17083fde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Website Model Evaluation:\n",
      "\n",
      "Accuracy: 0.8347826086956521\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      " Genuine Website       0.86      0.91      0.89       245\n",
      "Phishing Website       0.75      0.64      0.69       100\n",
      "\n",
      "        accuracy                           0.83       345\n",
      "       macro avg       0.81      0.78      0.79       345\n",
      "    weighted avg       0.83      0.83      0.83       345\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(MODEL_SAVE_PATH, map_location=device))\n",
    "model.eval()\n",
    "\n",
    "print(\"\\nFinal Website Model Evaluation:\\n\")\n",
    "print(\"Accuracy:\", accuracy_score(trues, preds))\n",
    "print(classification_report(\n",
    "    trues,\n",
    "    preds,\n",
    "    target_names=[\"Genuine Website\", \"Phishing Website\"]\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad90b59c-cf31-4966-81b3-10bffb8f688c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
